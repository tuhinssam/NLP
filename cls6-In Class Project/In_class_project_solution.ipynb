{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Project\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "The dataset has been taken from Kaggle. (https://www.kaggle.com/crowdflower/twitter-airline-sentiment/home)\n",
    "This is a dataset having tweets about 6 US Airlines along with their sentiments: positive, negative and neutral.\n",
    "\n",
    "You are provided with two files: ‚ÄòTweets-train.csv‚Äù and ‚ÄòTweets-test.csv‚Äù\n",
    "The train data contains about 11000 tweets and test contains 4000 tweets. You have to perform Sentiment Analysis on the dataset and also built a classifier on the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read the training using pandas module and select only the sentiment and text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data set\n",
    "import pandas as pd\n",
    "train=pd.read_csv('Tweets-train.csv')\n",
    "\n",
    "#Selecting only sentiment and tweet column from the entire data set\n",
    "train=train[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "‚Ä¢\tObserve randomly generated 10 tweets for each sentiment with respect to the following:\n",
    "o\tText contains references with ‚Äò@‚Äô\n",
    "o\tText contains links (http , https )\n",
    "o\tText contains punctuations\n",
    "o\tText contains Emoticons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USAirways it was customer service like I have never seen before!  Kudos to your organization.\n",
      "\n",
      "@AmericanAir I love your company and your staff is amazing. They just made an uncomfortable situation comfortable\n",
      "\n",
      "@united I appreciate the follow up.\n",
      "\n",
      "@JetBlue boarding the back of the airplane first. Like a boss. #sosmart #jetblue #frequentflyerappreciates #alsoyayforsnacks\n",
      "\n",
      "@AmericanAir mission accomplished today, Thank you!\n",
      "\n",
      "@united thnx\n",
      "\n",
      "@united thank you for following up!\n",
      "\n",
      "@JetBlue thanks so much!! ‚ù§Ô∏è‚ú® very relaxing flight!\n",
      "\n",
      "@USAirways thanks for seating me next to 2 hot athletes. This flight is significantly better now!\n",
      "\n",
      "@united awesome new plane flight 1701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#See some positive sentiments\n",
    "for each in train[train['airline_sentiment']==\"positive\"].sample(10,random_state=10)['text']:\n",
    "    print each \n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AmericanAir continues to win: I've never missed a flight before, but a nice little quiet gate change made it possible. Sheesh.\n",
      "\n",
      "@united is that all that matters, not the fact that we're at a different destination, we were put through a tremendous amount of stress,\n",
      "\n",
      "@USAirways your lack of customer service has shined. I need you to step up and get my lost baggage to delta. So they can return it to me.\n",
      "\n",
      "@united Terribly disappointed. Confirmed reservation delayed and your cust. service staff was not helpful in finding an alternate solution.\n",
      "\n",
      "@united what is this subtlety gate changes? Are you kidding with me?\n",
      "\n",
      "@SouthwestAir and now no wifi??? Come on.\n",
      "\n",
      "@JetBlue is flight 51 on 4/24/15 moved back? When I booked it said we arrive 11:31 but now it says 12:08 üò¢\n",
      "\n",
      "@AmericanAir complt incompetence on flt 295.Lav delay from a pln that lnded last nite, no internet and poor svc. Not what I expect from u.\n",
      "\n",
      "@united @annricord 0162431184663.\r\n",
      "3 of your agents said we would be refunded. Agents said United should never have sold us the ticket.\n",
      "\n",
      "@united I'm checked in, agent wouldn't tag my bags at 7am. Now I'm standing in line hell.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#See some negative sentiments\n",
    "for each in train[train['airline_sentiment']==\"negative\"].sample(10,random_state=10)['text']:\n",
    "    print each \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue you guys get rid of the hip hop stations on Sirius XM?\n",
      "\n",
      "@JetBlue deal!\n",
      "\n",
      "@united can I request a ticket change through twitter ?\n",
      "\n",
      "@united My mom left her Kindle on flight 1544 today. Burgundy case with a light. Seat 27D. Did anyone find it?\n",
      "\n",
      "@USAirways am 2. 1/2 hours from airport sure would like to talk to someone\n",
      "\n",
      "@JetBlue well I'm not sure I'm that bold! lol or are you saying you didn't believe me?? :P\n",
      "\n",
      "@united can you send me another confirmation email?\n",
      "\n",
      "@SouthwestAir first time flyer, scheduled a (round)trip. set on departure date not sure on returning date, policy/fees on changing Re Flight\n",
      "\n",
      "@SouthwestAir still haven't been able to get through, thanks for responding\n",
      "\n",
      "@USAirways we even offered to fly in to another airport and they said they couldn't do that. No explanation why they can't.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#See some neutral sentiments\n",
    "for each in train[train['airline_sentiment']==\"neutral\"].sample(10,random_state=10)['text']:\n",
    "    print each \n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the observations ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Data contains words starting with '@'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Data contains words having '#' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Data contains links 'https:....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data contains emoticons and punctuations such as ' , . ; ‚ù§Ô∏è‚ú® ! etc etc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The next step can be to clean the data and remove such things as they are not going to help in classifer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n",
      "\n",
      "virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n"
     ]
    }
   ],
   "source": [
    "#@ mentions\n",
    "import re\n",
    "\n",
    "print train.text[5]\n",
    "print \n",
    "print re.sub(r'@+','',train.text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n",
      "\n",
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel \n"
     ]
    }
   ],
   "source": [
    "#Links \n",
    "\n",
    "print train.text[10]\n",
    "print \n",
    "print re.sub('http?://[A-Za-z0-9./]+','',train.text[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS\n",
      "\n",
      " VirginAmerica amazing to me that we can t get any cold air from the vents   VX358  noair  worstflightever  roasted  SFOtoBOS\n",
      "\n",
      "\n",
      "@JetBlue thanks so much!! ‚ù§Ô∏è‚ú® very relaxing flight!\n",
      "\n",
      " JetBlue thanks so much             very relaxing flight \n"
     ]
    }
   ],
   "source": [
    "# selects only aplhabets numbers so that punctuations and emoticons are removed.\n",
    "\n",
    "print train.text[22]\n",
    "print \n",
    "print re.sub(\"[^a-zA-Z0-9]\", \" \",train.text[22])\n",
    "print \n",
    "print \n",
    "print train.text[5977]\n",
    "print \n",
    "print re.sub(\"[^a-zA-Z0-9]\", \" \",train.text[5977])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You have to prepare a function to clean all the above observed tokens from the tweet text.\n",
    "Save changes in a new column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tweet_cleaner(text):\n",
    "    text=re.sub(r'@+','',text)\n",
    "    text=re.sub('http?://[A-Za-z0-9./]+','',text)\n",
    "    text=re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    lower_case = text.lower()\n",
    "    words = tokenizer.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Cleaned-Text']=map(lambda x:tweet_cleaner(x),train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \n",
       "0  virginamerica plus you ve added commercials to...  \n",
       "1  virginamerica i didn t today must mean i need ...  \n",
       "2  virginamerica it s really aggressive to blast ...  \n",
       "3  virginamerica and it s a really big bad thing ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "List down the most common 15 words for each sentiment. Observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('to', 4326), ('i', 3313), ('the', 3021), ('a', 2344), ('flight', 2113), ('united', 2101), ('and', 2049), ('on', 2023), ('for', 1999), ('you', 1959), ('my', 1726), ('usairways', 1722), ('americanair', 1549), ('is', 1526), ('t', 1327)]\n",
      "\n",
      "neutral\n",
      "[('to', 1185), ('i', 1004), ('the', 730), ('a', 616), ('you', 561), ('jetblue', 540), ('united', 530), ('southwestair', 489), ('on', 479), ('for', 443), ('flight', 436), ('my', 391), ('is', 372), ('americanair', 363), ('in', 355)]\n",
      "\n",
      "positive\n",
      "[('the', 690), ('to', 675), ('you', 672), ('i', 555), ('for', 493), ('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('a', 385), ('united', 376), ('thank', 336), ('and', 306), ('flight', 269), ('my', 263), ('americanair', 254)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#See some words in All sentiments\n",
    "\n",
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Cleaned-Text']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print group_name\n",
    "    print Counter(words).most_common(15)\n",
    "    print \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We observe that most of the frequencies are of stopwords , so let's remove them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove Stopwords from all the tweets.\n",
    "Save changes in a new column and list down most common 15 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PreProcess import RemoveStopWords  #created in previous exercises \n",
    "train['Clean-Text-StopWords-Removed']=map(lambda x:RemoveStopWords(x),train['Cleaned-Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('flight', 2113), ('united', 2101), ('usairways', 1722), ('americanair', 1549), ('southwestair', 884), ('jetblue', 755), ('get', 728), ('cancelled', 648), ('service', 530), ('hours', 502), ('help', 443), ('customer', 428), ('time', 426), ('hold', 424), ('plane', 387)]\n",
      "\n",
      "neutral\n",
      "[('jetblue', 540), ('united', 530), ('southwestair', 489), ('flight', 436), ('americanair', 363), ('usairways', 302), ('get', 173), ('please', 132), ('virginamerica', 130), ('flights', 130), ('help', 121), ('thanks', 115), ('need', 114), ('would', 92), ('dm', 91)]\n",
      "\n",
      "positive\n",
      "[('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('united', 376), ('thank', 336), ('flight', 269), ('americanair', 254), ('usairways', 199), ('great', 165), ('service', 120), ('virginamerica', 114), ('love', 105), ('best', 85), ('customer', 85), ('good', 82)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Again let's see the counts of most common words after removing stopwords.\n",
    "\n",
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Clean-Text-StopWords-Removed']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print group_name\n",
    "    print Counter(words).most_common(15)\n",
    "    print \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove these words from all the tweets.\n",
    "\n",
    "americanair, united, delta, southwestair, jetblue, virginamerica, usairways, flight, plane\n",
    "\n",
    "Save changes in a new column and list down most common 15 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RemoveExplicitlyMentionedWords(string,listofWordsToRemove):\n",
    "    listOfAllWords=string.split(\" \")\n",
    "    listOfWords= [x for x in listOfAllWords if x not in listofWordsToRemove]\n",
    "    return (\" \".join(listOfWords)).strip()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_words_to_remove=['americanair','united','delta','southwestair','jetblue','virginamerica','usairways','flight','plane']\n",
    "train['Final-Wrangled-Text']=map(lambda x:RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),train['Clean-Text-StopWords-Removed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('get', 728), ('cancelled', 648), ('service', 530), ('hours', 502), ('help', 443), ('customer', 428), ('time', 426), ('hold', 424), ('delayed', 371), ('amp', 368), ('us', 364), ('still', 363), ('call', 334), ('hour', 324), ('one', 322)]\n",
      "\n",
      "neutral\n",
      "[('get', 173), ('please', 132), ('flights', 130), ('help', 121), ('thanks', 115), ('need', 114), ('would', 92), ('dm', 91), ('time', 80), ('tomorrow', 76), ('cancelled', 74), ('amp', 73), ('us', 72), ('know', 72), ('fleek', 70)]\n",
      "\n",
      "positive\n",
      "[('thanks', 448), ('thank', 336), ('great', 165), ('service', 120), ('love', 105), ('best', 85), ('customer', 85), ('good', 82), ('guys', 81), ('much', 77), ('get', 76), ('got', 71), ('awesome', 71), ('help', 65), ('time', 64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count Again words in All sentiments\n",
    "\n",
    "from collections import Counter\n",
    "for group_name,subset in train.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['Final-Wrangled-Text']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print group_name\n",
    "    print Counter(words).most_common(15)\n",
    "    print \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Encode Sentiments using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned-Text</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "      <th>SentimentLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        Cleaned-Text  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \\\n",
       "0  virginamerica plus added commercials experienc...   \n",
       "1  virginamerica today must mean need take anothe...   \n",
       "2  virginamerica really aggressive blast obnoxiou...   \n",
       "3                 virginamerica really big bad thing   \n",
       "\n",
       "                                 Final-Wrangled-Text  SentimentLabel  \n",
       "0            plus added commercials experience tacky               2  \n",
       "1             today must mean need take another trip               1  \n",
       "2  really aggressive blast obnoxious entertainmen...               0  \n",
       "3                               really big bad thing               0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l=LabelEncoder()\n",
    "train['SentimentLabel']=l.fit_transform(train['airline_sentiment'])\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we observe,\n",
    "0->neutral\n",
    "1->positive\n",
    "2->negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vectorize the Text Column (You can choose any vectorizer of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=vectorizer.fit_transform(train['Final-Wrangled-Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prepare a multiclass Classification model using any classification algorithm and create a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=train['SentimentLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Model Using Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read the test data and carry our data cleaning, encoding and vectorising operations on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('Tweets-test.csv')\n",
    "test=test[['airline_sentiment','text']]\n",
    "test['Cleaned-Text']=map(lambda x:tweet_cleaner(x),test['text'])\n",
    "test['Clean-Text-StopWords-Removed']=map(lambda x:RemoveStopWords(x),test['Cleaned-Text'])\n",
    "test['Final-Wrangled-Text']=map(lambda x:RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),test['Clean-Text-StopWords-Removed'])\n",
    "x_test=vectorizer.transform(test['Final-Wrangled-Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encoding label for test data as well\n",
    "test['SentimentLabel']=l.transform(test['airline_sentiment'])\n",
    "y_test=test['SentimentLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Predict the sentiments for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysaxe2\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def GetOrignalSentiment(val):\n",
    "    if val==0:\n",
    "        return 'negative'\n",
    "    elif val==1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "Result=test[['text','airline_sentiment']]\n",
    "Result['Predicted_sentiment']=map(lambda x:GetOrignalSentiment(x),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmericanAir why did you drop my call. Why don...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USAirways thanks for the seat that doesn't re...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AmericanAir wasn't just a delay. Your counter...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0  @AmericanAir why did you drop my call. Why don...          negative   \n",
       "1  @USAirways thanks for the seat that doesn't re...          negative   \n",
       "2  @AmericanAir wasn't just a delay. Your counter...          negative   \n",
       "\n",
       "  Predicted_sentiment  \n",
       "0            negative  \n",
       "1            negative  \n",
       "2            negative  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Print and explain the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "[[2396   79   33]\n",
      " [ 456  333   62]\n",
      " [ 225   51  365]]\n"
     ]
    }
   ],
   "source": [
    "print \"Confusion Matrix:\\n\\n\",metrics.confusion_matrix(Result['airline_sentiment'],Result['Predicted_sentiment'],labels=['negative','neutral','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual negative Predicted negative: 2396\n",
      "Actual negative Predicted neutral: 79\n",
      "Actual negative Predicted positive: 33\n",
      "Actual neutral Predicted negative: 456\n",
      "Actual neutral Predicted neutral: 333\n",
      "Actual neutral Predicted positive: 62\n",
      "Actual positive Predicted negative: 225\n",
      "Actual positive Predicted neutral: 51\n",
      "Actual positive Predicted positive: 365\n"
     ]
    }
   ],
   "source": [
    "#Explaning Confusion Matrix Elements\n",
    "\n",
    "for i,x in Result.groupby(['airline_sentiment','Predicted_sentiment']):\n",
    "    print \"Actual \"+ i[0]+ \" Predicted \"+i[1]+ \":\", len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute Accuracy of your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 77.35 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy :\n",
    "ActualNegativePrdictedNegative=2396\n",
    "ActualNeutralPrdictedNeutral=333\n",
    "ActualPositivePrdictedPositive=365\n",
    "TotalCorrect=ActualNegativePrdictedNegative+ActualNeutralPrdictedNeutral+ActualPositivePrdictedPositive\n",
    "print \"Accuracy=\",TotalCorrect*100.0/len(test) ,\"%\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
